import torch
import os
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

print("=" * 60)
print("ğŸš€ AI SERVER - GPU/CPU STATUS & CONFIGURATION CHECK")
print("=" * 60)

# Check CUDA availability
cuda_available = torch.cuda.is_available()
print(f"CUDA Available: {'âœ… YES' if cuda_available else 'âŒ NO'}")

if cuda_available:
    # GPU Information
    gpu_name = torch.cuda.get_device_name(0)
    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
    print(f"ğŸ¯ GPU Name: {gpu_name}")
    print(f"ğŸ’¾ GPU Memory: {gpu_memory:.1f} GB")
    print(f"ğŸ”¥ GPU Count: {torch.cuda.device_count()}")
    
    # Check GPU memory usage
    try:
        print(f"ğŸ“Š Memory Allocated: {torch.cuda.memory_allocated(0) / 1024**3:.2f} GB")
        print(f"ğŸ“ˆ Memory Cached: {torch.cuda.memory_reserved(0) / 1024**3:.2f} GB")
    except:
        print("ğŸ“Š Memory info: Available after model loading")
    
    print("\nğŸ® GPU MODE ENABLED - AI models sáº½ Æ°u tiÃªn sá»­ dá»¥ng GPU")
    
else:
    print("ğŸ’» GPU khÃ´ng cÃ³ sáºµn - AI models sáº½ cháº¡y trÃªn CPU")
    print("âš ï¸ Hiá»‡u suáº¥t cÃ³ thá»ƒ cháº­m hÆ¡n so vá»›i GPU")

# Check environment settings
print("\n" + "=" * 60)
print("âš™ï¸ ENVIRONMENT CONFIGURATION")
print("=" * 60)

force_cpu = os.getenv("FORCE_CPU_MODE", "False").lower() == "true"
print(f"Force CPU Mode: {'âœ… ON (GPU bá»‹ vÃ´ hiá»‡u hÃ³a)' if force_cpu else 'âŒ OFF (Æ¯u tiÃªn GPU)'}")

cuda_alloc = os.getenv("PYTORCH_CUDA_ALLOC_CONF", "Not set")
print(f"CUDA Alloc Config: {cuda_alloc}")

# Check API keys
api_key = os.getenv("GOOGLE_API_KEY", "Not set")
if api_key != "Not set" and len(api_key) > 20:
    print(f"Google API Key: âœ… Set ({api_key[:10]}...{api_key[-10:]})")
elif api_key != "Not set":
    print(f"Google API Key: âœ… Set")
else:
    print("Google API Key: âŒ Not set")

etherscan_key = os.getenv("ETHERSCAN_API_KEY", "Not set")
if etherscan_key != "Not set" and etherscan_key != "YourAPIKeyHere":
    print(f"Etherscan API Key: âœ… Set")
else:
    print("Etherscan API Key: âš ï¸ Using default/not set")

# Model status prediction
print("\n" + "=" * 60)
print("ğŸ¤– AI MODELS STATUS PREDICTION")
print("=" * 60)

print("ğŸ“š Study Chat (Gemini API): " + ("âœ… Ready" if api_key != "Not set" else "âŒ Need API key"))

if cuda_available and not force_cpu:
    print("ğŸ“Š Blockchain LLM: âœ… Will use GPU acceleration")
    print("ğŸ” Fraud Detection: âœ… Will use optimized processing")
else:
    print("ğŸ“Š Blockchain LLM: âš ï¸ Will use CPU (slower)")
    print("ğŸ” Fraud Detection: âœ… CPU-optimized mode")

print("ğŸ’° Finance Manager: âœ… Ready (No AI model required)")

print("\n" + "=" * 60)
if cuda_available and not force_cpu and api_key != "Not set":
    print("ğŸš€ OPTIMAL: ToÃ n bá»™ AI features sáº½ hoáº¡t Ä‘á»™ng vá»›i hiá»‡u suáº¥t tá»‘i Æ°u!")
elif api_key != "Not set":
    print("ğŸ‘ GOOD: AI features sáº½ hoáº¡t Ä‘á»™ng, GPU sáº½ tÄƒng tá»‘c khi cÃ³")
else:
    print("âš ï¸ WARNING: Cáº§n cáº¥u hÃ¬nh API keys Ä‘á»ƒ sá»­ dá»¥ng Ä‘áº§y Ä‘á»§ tÃ­nh nÄƒng")
print("=" * 60)
